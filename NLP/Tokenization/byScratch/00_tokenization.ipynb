{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMkw7PMcBM3BE5EO8yiSIbV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "from collections import defaultdict\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gdTj1gK13smS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Corpus"
      ],
      "metadata": {
        "id": "t9ee6Ze50Ixr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"manashjyotiborah/top-10000-movies-hosted-on-tmdb\")"
      ],
      "metadata": {
        "id": "XiztdtSU1D6y",
        "outputId": "f8a094af-e958-4c48-f4a9-2def0ce6ac21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/manashjyotiborah/top-10000-movies-hosted-on-tmdb?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16.9M/16.9M [00:00<00:00, 81.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overview_df = pd.read_csv(f'{path}/movies_dataset.csv', index_col='id')\n",
        "overview_df.dropna(axis=0, inplace=True)\n",
        "\n",
        "corpus = overview_df['overview'].to_list()\n",
        "corpus[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-WrCQWU3nZk",
        "outputId": "1903df56-248f-494f-c36a-1145ca210922"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Over many missions and against impossible odds, Dom Toretto and his family have outsmarted, out-nerved and outdriven every foe in their path. Now, they confront the most lethal opponent they've ever faced: A terrifying threat emerging from the shadows of the past who's fueled by blood revenge, and who is determined to shatter this family and destroy everything—and everyone—that Dom loves, forever.\",\n",
              " \"Tasked with extracting a family who is at the mercy of a Georgian gangster, Tyler Rake infiltrates one of the world's deadliest prisons in order to save them. But when the extraction gets hot, and the gangster dies in the heat of battle, his equally ruthless brother tracks down Rake and his team to Sydney, in order to get revenge.\",\n",
              " 'With the price on his head ever increasing, John Wick uncovers a path to defeating The High Table. But before he can earn his freedom, Wick must face off against a new enemy with powerful alliances across the globe and forces that turn old friends into foes.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]"
      ],
      "metadata": {
        "id": "nXEpv0H9wV1t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "UXiBNYimRZxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://github.com/vukrosic/courses/tree/main/llama4"
      ],
      "metadata": {
        "id": "_dckSzu298cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helpers\n",
        "END_OF_WORD = '/w'\n",
        "\n",
        "def get_slice(d:dict, n:int)->list:\n",
        "    return [(key, val) for key, val in zip(range(n), d.items())]\n"
      ],
      "metadata": {
        "id": "OeTmeHnZ8LS-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_chars(corpus):\n",
        "    unique_chars = set()\n",
        "    for overview in corpus:\n",
        "        for char in overview:\n",
        "            unique_chars.add(char)\n",
        "\n",
        "    vocab = list(unique_chars)\n",
        "    vocab.sort()\n",
        "    vocab.append(END_OF_WORD)\n",
        "\n",
        "    return vocab\n",
        "\n",
        "\n",
        "def get_word_splits(corpus):\n",
        "    word_splits = defaultdict(int)\n",
        "    for doc in corpus:\n",
        "        for word in doc.split(' '):\n",
        "            if word:\n",
        "                word_tuple = tuple(list(word) + [END_OF_WORD])\n",
        "                word_splits[word_tuple] += 1\n",
        "\n",
        "    return word_splits\n",
        "\n",
        "\n",
        "def get_pair_stats(splits:dict)->list:\n",
        "    pair_counts = defaultdict(int)\n",
        "    for word_tuple, freq in splits.items():\n",
        "        symbols = list(word_tuple)\n",
        "        for i in range(len(symbols)-1):\n",
        "            pair = (symbols[i], symbols[i+1])\n",
        "            pair_counts[pair] += freq\n",
        "    return pair_counts\n",
        "\n",
        "\n",
        "def merge_pair(pair_to_merge:tuple, splits:dict)->list:\n",
        "    new_splits = {}\n",
        "    (first, second) = pair_to_merge\n",
        "    merged_token = first + second\n",
        "    for word_tuple, freq in splits.items():\n",
        "        symbols = list(word_tuple)\n",
        "        new_symbols = []\n",
        "        i = 0\n",
        "        while i < len(symbols):\n",
        "            if i<len(symbols)-1 and symbols[i]==first and symbols[i+1]==second:\n",
        "                new_symbols.append(merged_token)\n",
        "                i += 2\n",
        "            else:\n",
        "                new_symbols.append(symbols[i])\n",
        "                i += 1\n",
        "        new_splits[tuple(new_symbols)] = freq\n",
        "    return new_splits\n",
        "\n"
      ],
      "metadata": {
        "id": "L32LHGbz4Jt2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = get_unique_chars(corpus)\n",
        "print(vocab[:10], len(vocab), sep='\\n')"
      ],
      "metadata": {
        "id": "kD-Zt38hw7Ss",
        "outputId": "701b6323-06d9-4e61-a092-5d7cb86a2ed8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\r', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(']\n",
            "129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_vocab = get_unique_chars(toy_corpus)\n",
        "print(toy_vocab, len(toy_vocab), sep='\\n')"
      ],
      "metadata": {
        "id": "5iwUN-xvxCN7",
        "outputId": "ce829d24-a8bf-4717-a04d-572ea0774a0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w']\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_splits = get_word_splits(corpus)\n",
        "get_slice(word_splits, 10)"
      ],
      "metadata": {
        "id": "Mp3dvOgExiai",
        "outputId": "54296646-7ec1-4316-c89b-6b4c4dd1d568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, (('O', 'v', 'e', 'r', '/w'), 17)),\n",
              " (1, (('m', 'a', 'n', 'y', '/w'), 104)),\n",
              " (2, (('m', 'i', 's', 's', 'i', 'o', 'n', 's', '/w'), 14)),\n",
              " (3, (('a', 'n', 'd', '/w'), 13235)),\n",
              " (4, (('a', 'g', 'a', 'i', 'n', 's', 't', '/w'), 470)),\n",
              " (5, (('i', 'm', 'p', 'o', 's', 's', 'i', 'b', 'l', 'e', '/w'), 48)),\n",
              " (6, (('o', 'd', 'd', 's', ',', '/w'), 17)),\n",
              " (7, (('D', 'o', 'm', '/w'), 7)),\n",
              " (8, (('T', 'o', 'r', 'e', 't', 't', 'o', '/w'), 4)),\n",
              " (9, (('h', 'i', 's', '/w'), 6924))]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_word_splits = get_word_splits(toy_corpus)\n",
        "toy_word_splits"
      ],
      "metadata": {
        "id": "n7yeJ-0dxoK-",
        "outputId": "47d2fbfc-749c-4500-b63f-2043d2534491",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {('T', 'h', 'i', 's', '/w'): 2,\n",
              "             ('i', 's', '/w'): 3,\n",
              "             ('t', 'h', 'e', '/w'): 4,\n",
              "             ('f', 'i', 'r', 's', 't', '/w'): 2,\n",
              "             ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '/w'): 2,\n",
              "             ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '/w'): 1,\n",
              "             ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1,\n",
              "             ('A', 'n', 'd', '/w'): 1,\n",
              "             ('t', 'h', 'i', 's', '/w'): 2,\n",
              "             ('t', 'h', 'i', 'r', 'd', '/w'): 1,\n",
              "             ('o', 'n', 'e', '.', '/w'): 1,\n",
              "             ('I', 's', '/w'): 1,\n",
              "             ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '/w'): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pair_stats = get_pair_stats(word_splits)\n",
        "get_slice(pair_stats, 10)"
      ],
      "metadata": {
        "id": "vGd8qgfnxzET",
        "outputId": "60a5c46a-3d9c-4003-cfc9-c141e0dd74e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, (('O', 'v'), 30)),\n",
              " (1, (('v', 'e'), 15729)),\n",
              " (2, (('e', 'r'), 39971)),\n",
              " (3, (('r', '/w'), 28195)),\n",
              " (4, (('m', 'a'), 9653)),\n",
              " (5, (('a', 'n'), 37733)),\n",
              " (6, (('n', 'y'), 1236)),\n",
              " (7, (('y', '/w'), 22819)),\n",
              " (8, (('m', 'i'), 5564)),\n",
              " (9, (('i', 's'), 23459))]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_pair_stats = get_pair_stats(toy_word_splits)\n",
        "toy_pair_stats"
      ],
      "metadata": {
        "id": "4QDdiyt8x1pr",
        "outputId": "dcaed673-40f3-4a46-bec8-cee4666fd451",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {('T', 'h'): 2,\n",
              "             ('h', 'i'): 5,\n",
              "             ('i', 's'): 7,\n",
              "             ('s', '/w'): 8,\n",
              "             ('t', 'h'): 7,\n",
              "             ('h', 'e'): 4,\n",
              "             ('e', '/w'): 4,\n",
              "             ('f', 'i'): 2,\n",
              "             ('i', 'r'): 3,\n",
              "             ('r', 's'): 2,\n",
              "             ('s', 't'): 2,\n",
              "             ('t', '/w'): 3,\n",
              "             ('d', 'o'): 4,\n",
              "             ('o', 'c'): 4,\n",
              "             ('c', 'u'): 4,\n",
              "             ('u', 'm'): 4,\n",
              "             ('m', 'e'): 4,\n",
              "             ('e', 'n'): 4,\n",
              "             ('n', 't'): 4,\n",
              "             ('t', '.'): 2,\n",
              "             ('.', '/w'): 3,\n",
              "             ('s', 'e'): 1,\n",
              "             ('e', 'c'): 1,\n",
              "             ('c', 'o'): 1,\n",
              "             ('o', 'n'): 2,\n",
              "             ('n', 'd'): 2,\n",
              "             ('d', '/w'): 3,\n",
              "             ('A', 'n'): 1,\n",
              "             ('r', 'd'): 1,\n",
              "             ('n', 'e'): 1,\n",
              "             ('e', '.'): 1,\n",
              "             ('I', 's'): 1,\n",
              "             ('t', '?'): 1,\n",
              "             ('?', '/w'): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fun(corpus:list, num_merges:int=15, verbose=False)->list:\n",
        "    merges = {}\n",
        "    vocab = get_unique_chars(corpus)\n",
        "    current_splits = get_word_splits(corpus)\n",
        "    for i in range(num_merges):\n",
        "        # 1. Calculate Pair Frequencies\n",
        "        pair_stats = get_pair_stats(current_splits)\n",
        "        if not pair_stats:\n",
        "            print('No more pairs to merge.')\n",
        "            break\n",
        "\n",
        "        # 2. Find Best Pair\n",
        "        # The 'max' function iterates over all key-value pairs in the 'pair_stats' dictionary\n",
        "        # The 'key=pair_stats.get' tells 'max' to use the frequency (value) for comparison, not the pair (key) itself\n",
        "        # This way, 'max' selects the pair with the highest frequency\n",
        "        best_pair = max(pair_stats, key=pair_stats.get)\n",
        "        best_freq = pair_stats[best_pair]\n",
        "\n",
        "        # 3. Merge the Best Pair\n",
        "        current_splits = merge_pair(best_pair, current_splits)\n",
        "        new_token = best_pair[0] + best_pair[1]\n",
        "\n",
        "        # 4. Update Vocabulary\n",
        "        vocab.append(new_token)\n",
        "\n",
        "        # 5. Store Merge Rule\n",
        "        merges[best_pair] = new_token\n",
        "\n",
        "        if verbose:\n",
        "            print(f'Merge Iteration {i+1}/{num_merges}')\n",
        "            sorted_pairs = sorted(pair_stats.items(), key=lambda item: item[1], reverse=True)\n",
        "            print(f'Top 5 Pair Frequencies: {sorted_pairs[:5]}')\n",
        "            print(f'Found Best Pair: {best_pair} with Frequency: {best_freq}')\n",
        "            print(f\"Merging {best_pair} into '{new_token}'\")\n",
        "            print(f'Splits after merge: {current_splits}')\n",
        "            print(f\"Updated Vocabulary: {vocab}\")\n",
        "            print(f'Updated Merges: {merges}')\n",
        "            print('-' * 30)\n",
        "\n",
        "    return vocab, current_splits\n",
        "\n"
      ],
      "metadata": {
        "id": "qWwP5oVmQvMl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab, splits = fun(toy_corpus)"
      ],
      "metadata": {
        "id": "aJuxAOQO7auZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "id": "RqTytIKyKlB5",
        "outputId": "683bd2f3-1131-4839-f9e0-c718215d0086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " '.',\n",
              " '?',\n",
              " 'A',\n",
              " 'I',\n",
              " 'T',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'h',\n",
              " 'i',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " '/w',\n",
              " 's/w',\n",
              " 'is/w',\n",
              " 'th',\n",
              " 'the',\n",
              " 'the/w',\n",
              " 'do',\n",
              " 'doc',\n",
              " 'docu',\n",
              " 'docum',\n",
              " 'docume',\n",
              " 'documen',\n",
              " 'document',\n",
              " 'ir',\n",
              " './w',\n",
              " 'd/w']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_unique_chars(toy_corpus) # initial vocab"
      ],
      "metadata": {
        "id": "1QYvNNgrKzBa",
        "outputId": "c8742950-87e6-4d9f-9043-90ee6b31511f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " '.',\n",
              " '?',\n",
              " 'A',\n",
              " 'I',\n",
              " 'T',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'h',\n",
              " 'i',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " '/w']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits"
      ],
      "metadata": {
        "id": "ZcoVLcfB7fQB",
        "outputId": "1137701c-4439-4da0-cacf-923e6ac71b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('T', 'h', 'is/w'): 2,\n",
              " ('is/w',): 3,\n",
              " ('the/w',): 4,\n",
              " ('f', 'ir', 's', 't', '/w'): 2,\n",
              " ('document', './w'): 2,\n",
              " ('document', '/w'): 1,\n",
              " ('s', 'e', 'c', 'o', 'n', 'd/w'): 1,\n",
              " ('A', 'n', 'd/w'): 1,\n",
              " ('th', 'is/w'): 2,\n",
              " ('th', 'ir', 'd/w'): 1,\n",
              " ('o', 'n', 'e', './w'): 1,\n",
              " ('I', 's/w'): 1,\n",
              " ('document', '?', '/w'): 1}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_splits(toy_corpus)"
      ],
      "metadata": {
        "id": "IHqJWsfXKhhP",
        "outputId": "16fb046a-36be-48b0-9462-0f00e8315e7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {('T', 'h', 'i', 's', '/w'): 2,\n",
              "             ('i', 's', '/w'): 3,\n",
              "             ('t', 'h', 'e', '/w'): 4,\n",
              "             ('f', 'i', 'r', 's', 't', '/w'): 2,\n",
              "             ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '/w'): 2,\n",
              "             ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '/w'): 1,\n",
              "             ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1,\n",
              "             ('A', 'n', 'd', '/w'): 1,\n",
              "             ('t', 'h', 'i', 's', '/w'): 2,\n",
              "             ('t', 'h', 'i', 'r', 'd', '/w'): 1,\n",
              "             ('o', 'n', 'e', '.', '/w'): 1,\n",
              "             ('I', 's', '/w'): 1,\n",
              "             ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '/w'): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ],
      "metadata": {
        "id": "nd6Ao1BnKrZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from typing import Tuple, Optional"
      ],
      "metadata": {
        "id": "Z-bSvhdzOVkw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128  # Dimensionality of the model's hidden states\n",
        "num_attention_heads = 16 # Total number of query heads\n",
        "num_key_value_heads = 4  # Number of key/value heads (for GQA)\n",
        "head_dim = hidden_size // num_attention_heads # Dimension of each attention head\n",
        "max_position_embeddings = 256 # Maximum sequence length the model expects\n",
        "rope_theta = 10000.0 # Base for RoPE frequency calculation\n",
        "rms_norm_eps = 1e-5 # Epsilon for RMSNorm\n",
        "attention_bias = False # Whether to use bias in Q\n",
        "attention_dropout = 0.0 # Dropout probability for attention weights\n",
        "use_qk_norm = True # Whether to apply L2 norm to Q and K before attention\n",
        "\n",
        "# Sample Input\n",
        "batch_size = 2\n",
        "sequence_length = 10\n",
        "hidden_states = torch.randn(batch_size, sequence_length, hidden_size)\n",
        "# Create position IDs for each token in the sequence, repeated for each batch\n",
        "# torch.arange(0, sequence_length) generates a 1D tensor with values from 0 to sequence_length-1\n",
        "# The unsqueeze(0) adds an extra dimension at the 0th position, making it (1, sequence_length)\n",
        "# This allows repeat(batch_size, 1) to create a tensor of shape (batch_size, sequence_length)\n",
        "position_ids = torch.arange(0, sequence_length).unsqueeze(0).repeat(batch_size, 1) # Shape: (batch_size, sequence_length)\n",
        "# Simple causal mask (upper triangular) for demonstration\n",
        "# In reality, Llama4 uses a more complex mask creation including padding handling\n",
        "attention_mask = torch.triu(torch.ones(sequence_length, sequence_length) * -torch.inf, diagonal=1)\n",
        "attention_mask = attention_mask.unsqueeze(0).unsqueeze(0) # Shape: (1, 1, sequence_length, sequence_length)\n",
        "attention_mask = attention_mask.expand(batch_size, 1, -1, -1) # Shape: (batch_size, 1, sequence_length, sequence_length)"
      ],
      "metadata": {
        "id": "4HdQ5UCaOWFc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Sample Input Shapes:')\n",
        "print(f'\\thidden_states: {hidden_states.shape}')\n",
        "print(f'\\tposition_ids: {position_ids.shape}')\n",
        "print(f'\\tattention_mask: {attention_mask.shape}')"
      ],
      "metadata": {
        "id": "CTLihBIgQa-u",
        "outputId": "95d41f1d-31fc-4f95-9aca-94cc0eb5f423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Input Shapes:\n",
            "\thidden_states: torch.Size([2, 10, 128])\n",
            "\tposition_ids: torch.Size([2, 10])\n",
            "\tattention_mask: torch.Size([2, 1, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define projection layers\n",
        "q_proj = nn.Linear(hidden_size, num_attention_heads*head_dim, bias=attention_bias)\n",
        "k_proj = nn.Linear(hidden_size, num_key_value_heads*head_dim, bias=attention_bias)\n",
        "v_proj = nn.Linear(hidden_size, num_key_value_heads*head_dim, bias=attention_bias)\n",
        "o_proj = nn.Linear(num_attention_heads*head_dim, hidden_size, bias=attention_bias)"
      ],
      "metadata": {
        "id": "Q7MqddrXQgLC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate projections\n",
        "query_states = q_proj(hidden_states)\n",
        "key_states = k_proj(hidden_states)\n",
        "value_states = v_proj(hidden_states)"
      ],
      "metadata": {
        "id": "Qu9QTFPxQypj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape Q, K, V for multi-head attention\n",
        "# Target shape: (batch_size, num_heads, sequence_length, head_dim)\n",
        "query_states = query_states.view(batch_size, sequence_length, num_attention_heads, head_dim).transpose(1, 2)\n",
        "key_states = key_states.view(batch_size, sequence_length, num_key_value_heads, head_dim).transpose(1, 2)\n",
        "value_states = value_states.view(batch_size, sequence_length, num_key_value_heads, head_dim).transpose(1, 2)"
      ],
      "metadata": {
        "id": "K-7Je2-6Q4LC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Projected Shapes:')\n",
        "print(f'\\tquery_states: {query_states.shape}') # (batch_size, num_attention_heads, sequence_length, head_dim)\n",
        "print(f'\\tkey_states: {key_states.shape}')     # (batch_size, num_key_value_heads, sequence_length, head_dim)\n",
        "print(f'\\tvalue_states: {value_states.shape}')   # (batch_size, num_key_value_heads, sequence_length, head_dim)"
      ],
      "metadata": {
        "id": "LK6oIUt7REl6",
        "outputId": "5bc94791-2a1c-4343-8bc9-f0b5ef1a901b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Projected Shapes:\n",
            "\tquery_states: torch.Size([2, 16, 10, 8])\n",
            "\tkey_states: torch.Size([2, 4, 10, 8])\n",
            "\tvalue_states: torch.Size([2, 4, 10, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_key_value_groups = num_attention_heads // num_key_value_heads\n",
        "print(f'Num Key/Value Groups (Q heads per K/V head): {num_key_value_groups}')"
      ],
      "metadata": {
        "id": "phct3AavRJRR",
        "outputId": "9f291fcd-8e2a-46b6-b23c-13eee589f3ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Key/Value Groups (Q heads per K/V head): 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fx01LDOARy-b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}