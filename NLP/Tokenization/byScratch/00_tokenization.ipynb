{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN+pLt3CKidojZ8NKzwezAv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "from collections import defaultdict\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gdTj1gK13smS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Corpus"
      ],
      "metadata": {
        "id": "t9ee6Ze50Ixr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"manashjyotiborah/top-10000-movies-hosted-on-tmdb\")"
      ],
      "metadata": {
        "id": "XiztdtSU1D6y",
        "outputId": "4aed8985-1128-45f1-8638-4bbce23ca708",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/manashjyotiborah/top-10000-movies-hosted-on-tmdb?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16.9M/16.9M [00:00<00:00, 137MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overview_df = pd.read_csv(f'{path}/movies_dataset.csv', index_col='id')\n",
        "overview_df.dropna(axis=0, inplace=True)\n",
        "\n",
        "corpus = overview_df['overview'].to_list()\n",
        "corpus[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-WrCQWU3nZk",
        "outputId": "ce470881-19e3-4f8b-bce1-25a0404d4524"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Over many missions and against impossible odds, Dom Toretto and his family have outsmarted, out-nerved and outdriven every foe in their path. Now, they confront the most lethal opponent they've ever faced: A terrifying threat emerging from the shadows of the past who's fueled by blood revenge, and who is determined to shatter this family and destroy everything—and everyone—that Dom loves, forever.\",\n",
              " \"Tasked with extracting a family who is at the mercy of a Georgian gangster, Tyler Rake infiltrates one of the world's deadliest prisons in order to save them. But when the extraction gets hot, and the gangster dies in the heat of battle, his equally ruthless brother tracks down Rake and his team to Sydney, in order to get revenge.\",\n",
              " 'With the price on his head ever increasing, John Wick uncovers a path to defeating The High Table. But before he can earn his freedom, Wick must face off against a new enemy with powerful alliances across the globe and forces that turn old friends into foes.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]"
      ],
      "metadata": {
        "id": "nXEpv0H9wV1t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "UXiBNYimRZxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://github.com/vukrosic/courses/tree/main/llama4"
      ],
      "metadata": {
        "id": "_dckSzu298cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helpers\n",
        "\n",
        "def get_slice(d:dict, n:int)->list:\n",
        "    return [(key, val) for key, val in zip(range(n), d.items())]\n"
      ],
      "metadata": {
        "id": "OeTmeHnZ8LS-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "END_OF_WORD = '/w'"
      ],
      "metadata": {
        "id": "jlQ-EfmQ7_X_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_chars(corpus):\n",
        "    unique_chars = set()\n",
        "    for overview in corpus:\n",
        "        for char in overview:\n",
        "            unique_chars.add(char)\n",
        "\n",
        "    vocab = list(unique_chars)\n",
        "    vocab.sort()\n",
        "    vocab.append(END_OF_WORD)\n",
        "\n",
        "    return vocab\n",
        "\n",
        "\n",
        "def get_word_splits(corpus):\n",
        "    word_splits = defaultdict(int)\n",
        "    for doc in corpus:\n",
        "        for word in doc.split(' '):\n",
        "            if word:\n",
        "                word_tuple = tuple(list(word) + [END_OF_WORD])\n",
        "                word_splits[word_tuple] += 1\n",
        "\n",
        "    return word_splits\n",
        "\n",
        "\n",
        "def get_pair_stats(splits:dict)->list:\n",
        "    pair_counts = defaultdict(int)\n",
        "    for word_tuple, freq in splits.items():\n",
        "        symbols = list(word_tuple)\n",
        "        for i in range(len(symbols)-1):\n",
        "            pair = (symbols[i], symbols[i+1])\n",
        "            pair_counts[pair] += freq\n",
        "    return pair_counts\n",
        "\n",
        "\n",
        "def merge_pair(pair_to_merge:tuple, splits:dict)->list:\n",
        "    new_splits = {}\n",
        "    (first, second) = pair_to_merge\n",
        "    merged_token = first + second\n",
        "    for word_tuple, freq in splits.items():\n",
        "        symbols = list(word_tuple)\n",
        "        new_symbols = []\n",
        "        i = 0\n",
        "        while i < len(symbols):\n",
        "            if i<len(symbols)-1 and symbols[i]==first and symbols[i+1]==second:\n",
        "                new_symbols.append(merged_token)\n",
        "                i += 2\n",
        "            else:\n",
        "                new_symbols.append(symbols[i])\n",
        "                i += 1\n",
        "        new_splits[tuple(new_symbols)] = freq\n",
        "    return new_splits\n",
        "\n"
      ],
      "metadata": {
        "id": "L32LHGbz4Jt2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = get_unique_chars(corpus)\n",
        "print(vocab[:10], len(vocab), sep='\\n')"
      ],
      "metadata": {
        "id": "kD-Zt38hw7Ss",
        "outputId": "807b1bce-b495-4863-c12f-251747d151fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\r', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(']\n",
            "129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_vocab = get_unique_chars(toy_corpus)\n",
        "print(toy_vocab, len(toy_vocab), sep='\\n')"
      ],
      "metadata": {
        "id": "5iwUN-xvxCN7",
        "outputId": "5518cb85-08c5-4709-f7b3-e219a2cd9b60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w']\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_splits = get_word_splits(corpus)\n",
        "get_slice(word_splits, 10)"
      ],
      "metadata": {
        "id": "Mp3dvOgExiai",
        "outputId": "e1e12cb8-4945-4883-aac2-2f30c4dcdcd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, (('O', 'v', 'e', 'r', '/w'), 17)),\n",
              " (1, (('m', 'a', 'n', 'y', '/w'), 104)),\n",
              " (2, (('m', 'i', 's', 's', 'i', 'o', 'n', 's', '/w'), 14)),\n",
              " (3, (('a', 'n', 'd', '/w'), 13235)),\n",
              " (4, (('a', 'g', 'a', 'i', 'n', 's', 't', '/w'), 470)),\n",
              " (5, (('i', 'm', 'p', 'o', 's', 's', 'i', 'b', 'l', 'e', '/w'), 48)),\n",
              " (6, (('o', 'd', 'd', 's', ',', '/w'), 17)),\n",
              " (7, (('D', 'o', 'm', '/w'), 7)),\n",
              " (8, (('T', 'o', 'r', 'e', 't', 't', 'o', '/w'), 4)),\n",
              " (9, (('h', 'i', 's', '/w'), 6924))]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_word_splits = get_word_splits(toy_corpus)\n",
        "toy_word_splits"
      ],
      "metadata": {
        "id": "n7yeJ-0dxoK-",
        "outputId": "ace4ce2b-6e5e-4d42-81f4-6bedbea2f939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {('T', 'h', 'i', 's', '/w'): 2,\n",
              "             ('i', 's', '/w'): 3,\n",
              "             ('t', 'h', 'e', '/w'): 4,\n",
              "             ('f', 'i', 'r', 's', 't', '/w'): 2,\n",
              "             ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '/w'): 2,\n",
              "             ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '/w'): 1,\n",
              "             ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1,\n",
              "             ('A', 'n', 'd', '/w'): 1,\n",
              "             ('t', 'h', 'i', 's', '/w'): 2,\n",
              "             ('t', 'h', 'i', 'r', 'd', '/w'): 1,\n",
              "             ('o', 'n', 'e', '.', '/w'): 1,\n",
              "             ('I', 's', '/w'): 1,\n",
              "             ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '/w'): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pair_stats = get_pair_stats(word_splits)\n",
        "get_slice(pair_stats, 10)"
      ],
      "metadata": {
        "id": "vGd8qgfnxzET",
        "outputId": "19b8957c-6ab3-4579-d9e6-758180981928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, (('O', 'v'), 30)),\n",
              " (1, (('v', 'e'), 15729)),\n",
              " (2, (('e', 'r'), 39971)),\n",
              " (3, (('r', '/w'), 28195)),\n",
              " (4, (('m', 'a'), 9653)),\n",
              " (5, (('a', 'n'), 37733)),\n",
              " (6, (('n', 'y'), 1236)),\n",
              " (7, (('y', '/w'), 22819)),\n",
              " (8, (('m', 'i'), 5564)),\n",
              " (9, (('i', 's'), 23459))]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_pair_stats = get_pair_stats(toy_word_splits)\n",
        "toy_pair_stats"
      ],
      "metadata": {
        "id": "4QDdiyt8x1pr",
        "outputId": "ca557110-ea87-46d0-962a-8f510586a052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {('T', 'h'): 2,\n",
              "             ('h', 'i'): 5,\n",
              "             ('i', 's'): 7,\n",
              "             ('s', '/w'): 8,\n",
              "             ('t', 'h'): 7,\n",
              "             ('h', 'e'): 4,\n",
              "             ('e', '/w'): 4,\n",
              "             ('f', 'i'): 2,\n",
              "             ('i', 'r'): 3,\n",
              "             ('r', 's'): 2,\n",
              "             ('s', 't'): 2,\n",
              "             ('t', '/w'): 3,\n",
              "             ('d', 'o'): 4,\n",
              "             ('o', 'c'): 4,\n",
              "             ('c', 'u'): 4,\n",
              "             ('u', 'm'): 4,\n",
              "             ('m', 'e'): 4,\n",
              "             ('e', 'n'): 4,\n",
              "             ('n', 't'): 4,\n",
              "             ('t', '.'): 2,\n",
              "             ('.', '/w'): 3,\n",
              "             ('s', 'e'): 1,\n",
              "             ('e', 'c'): 1,\n",
              "             ('c', 'o'): 1,\n",
              "             ('o', 'n'): 2,\n",
              "             ('n', 'd'): 2,\n",
              "             ('d', '/w'): 3,\n",
              "             ('A', 'n'): 1,\n",
              "             ('r', 'd'): 1,\n",
              "             ('n', 'e'): 1,\n",
              "             ('e', '.'): 1,\n",
              "             ('I', 's'): 1,\n",
              "             ('t', '?'): 1,\n",
              "             ('?', '/w'): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fun(corpus:list, num_merges:int=15):\n",
        "    merges = {}\n",
        "    vocab = get_unique_chars(corpus)\n",
        "    current_splits = get_word_splits(corpus)\n",
        "    for i in range(num_merges):\n",
        "        print(f'\\nMerge Iteration {i+1}/{num_merges}')\n",
        "\n",
        "        # 1. Calculate Pair Frequencies\n",
        "        pair_stats = get_pair_stats(current_splits)\n",
        "        if not pair_stats:\n",
        "            print('No more pairs to merge.')\n",
        "            break\n",
        "        # Optional: Print top 5 pairs for inspection\n",
        "        sorted_pairs = sorted(pair_stats.items(), key=lambda item: item[1], reverse=True)\n",
        "        print(f'Top 5 Pair Frequencies: {sorted_pairs[:5]}')\n",
        "\n",
        "        # 2. Find Best Pair\n",
        "        # The 'max' function iterates over all key-value pairs in the 'pair_stats' dictionary\n",
        "        # The 'key=pair_stats.get' tells 'max' to use the frequency (value) for comparison, not the pair (key) itself\n",
        "        # This way, 'max' selects the pair with the highest frequency\n",
        "        best_pair = max(pair_stats, key=pair_stats.get)\n",
        "        best_freq = pair_stats[best_pair]\n",
        "        print(f'Found Best Pair: {best_pair} with Frequency: {best_freq}')\n",
        "\n",
        "        # 3. Merge the Best Pair\n",
        "        current_splits = merge_pair(best_pair, current_splits)\n",
        "        new_token = best_pair[0] + best_pair[1]\n",
        "        print(f\"Merging {best_pair} into '{new_token}'\")\n",
        "        print(f'Splits after merge: {current_splits}')\n",
        "\n",
        "        # 4. Update Vocabulary\n",
        "        vocab.append(new_token)\n",
        "        print(f\"Updated Vocabulary: {vocab}\")\n",
        "\n",
        "        # 5. Store Merge Rule\n",
        "        merges[best_pair] = new_token\n",
        "        print(f'Updated Merges: {merges}')\n",
        "        print('-' * 30)\n"
      ],
      "metadata": {
        "id": "qWwP5oVmQvMl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fun(toy_corpus)"
      ],
      "metadata": {
        "id": "aJuxAOQO7auZ",
        "outputId": "9fd2b945-248a-4893-a50f-168e1cadacf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Merge Iteration 1/15\n",
            "Top 5 Pair Frequencies: [(('s', '/w'), 8), (('i', 's'), 7), (('t', 'h'), 7), (('h', 'i'), 5), (('h', 'e'), 4)]\n",
            "Found Best Pair: ('s', '/w') with Frequency: 8\n",
            "Merging ('s', '/w') into 's/w'\n",
            "Splits after merge: {('T', 'h', 'i', 's/w'): 2, ('i', 's/w'): 3, ('t', 'h', 'e', '/w'): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '/w'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('t', 'h', 'i', 's/w'): 2, ('t', 'h', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w']\n",
            "Updated Merges: {('s', '/w'): 's/w'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 2/15\n",
            "Top 5 Pair Frequencies: [(('i', 's/w'), 7), (('t', 'h'), 7), (('h', 'i'), 5), (('h', 'e'), 4), (('e', '/w'), 4)]\n",
            "Found Best Pair: ('i', 's/w') with Frequency: 7\n",
            "Merging ('i', 's/w') into 'is/w'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('t', 'h', 'e', '/w'): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '/w'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('t', 'h', 'is/w'): 2, ('t', 'h', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 3/15\n",
            "Top 5 Pair Frequencies: [(('t', 'h'), 7), (('h', 'is/w'), 4), (('h', 'e'), 4), (('e', '/w'), 4), (('d', 'o'), 4)]\n",
            "Found Best Pair: ('t', 'h') with Frequency: 7\n",
            "Merging ('t', 'h') into 'th'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('th', 'e', '/w'): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '/w'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 4/15\n",
            "Top 5 Pair Frequencies: [(('th', 'e'), 4), (('e', '/w'), 4), (('d', 'o'), 4), (('o', 'c'), 4), (('c', 'u'), 4)]\n",
            "Found Best Pair: ('th', 'e') with Frequency: 4\n",
            "Merging ('th', 'e') into 'the'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the', '/w'): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '/w'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 5/15\n",
            "Top 5 Pair Frequencies: [(('the', '/w'), 4), (('d', 'o'), 4), (('o', 'c'), 4), (('c', 'u'), 4), (('u', 'm'), 4)]\n",
            "Found Best Pair: ('the', '/w') with Frequency: 4\n",
            "Merging ('the', '/w') into 'the/w'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '/w'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 6/15\n",
            "Top 5 Pair Frequencies: [(('d', 'o'), 4), (('o', 'c'), 4), (('c', 'u'), 4), (('u', 'm'), 4), (('m', 'e'), 4)]\n",
            "Found Best Pair: ('d', 'o') with Frequency: 4\n",
            "Merging ('d', 'o') into 'do'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('do', 'c', 'u', 'm', 'e', 'n', 't', '.', '/w'): 2, ('do', 'c', 'u', 'm', 'e', 'n', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('do', 'c', 'u', 'm', 'e', 'n', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w', 'do']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w', ('d', 'o'): 'do'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 7/15\n",
            "Top 5 Pair Frequencies: [(('do', 'c'), 4), (('c', 'u'), 4), (('u', 'm'), 4), (('m', 'e'), 4), (('e', 'n'), 4)]\n",
            "Found Best Pair: ('do', 'c') with Frequency: 4\n",
            "Merging ('do', 'c') into 'doc'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('doc', 'u', 'm', 'e', 'n', 't', '.', '/w'): 2, ('doc', 'u', 'm', 'e', 'n', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('doc', 'u', 'm', 'e', 'n', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w', 'do', 'doc']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w', ('d', 'o'): 'do', ('do', 'c'): 'doc'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 8/15\n",
            "Top 5 Pair Frequencies: [(('doc', 'u'), 4), (('u', 'm'), 4), (('m', 'e'), 4), (('e', 'n'), 4), (('n', 't'), 4)]\n",
            "Found Best Pair: ('doc', 'u') with Frequency: 4\n",
            "Merging ('doc', 'u') into 'docu'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('docu', 'm', 'e', 'n', 't', '.', '/w'): 2, ('docu', 'm', 'e', 'n', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('docu', 'm', 'e', 'n', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w', 'do', 'doc', 'docu']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 9/15\n",
            "Top 5 Pair Frequencies: [(('docu', 'm'), 4), (('m', 'e'), 4), (('e', 'n'), 4), (('n', 't'), 4), (('i', 'r'), 3)]\n",
            "Found Best Pair: ('docu', 'm') with Frequency: 4\n",
            "Merging ('docu', 'm') into 'docum'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('docum', 'e', 'n', 't', '.', '/w'): 2, ('docum', 'e', 'n', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('docum', 'e', 'n', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w', 'do', 'doc', 'docu', 'docum']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 10/15\n",
            "Top 5 Pair Frequencies: [(('docum', 'e'), 4), (('e', 'n'), 4), (('n', 't'), 4), (('i', 'r'), 3), (('t', '/w'), 3)]\n",
            "Found Best Pair: ('docum', 'e') with Frequency: 4\n",
            "Merging ('docum', 'e') into 'docume'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('docume', 'n', 't', '.', '/w'): 2, ('docume', 'n', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('docume', 'n', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w', 'do', 'doc', 'docu', 'docum', 'docume']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 11/15\n",
            "Top 5 Pair Frequencies: [(('docume', 'n'), 4), (('n', 't'), 4), (('i', 'r'), 3), (('t', '/w'), 3), (('.', '/w'), 3)]\n",
            "Found Best Pair: ('docume', 'n') with Frequency: 4\n",
            "Merging ('docume', 'n') into 'documen'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('documen', 't', '.', '/w'): 2, ('documen', 't', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('documen', 't', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w', 'do', 'doc', 'docu', 'docum', 'docume', 'documen']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume', ('docume', 'n'): 'documen'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 12/15\n",
            "Top 5 Pair Frequencies: [(('documen', 't'), 4), (('i', 'r'), 3), (('t', '/w'), 3), (('.', '/w'), 3), (('d', '/w'), 3)]\n",
            "Found Best Pair: ('documen', 't') with Frequency: 4\n",
            "Merging ('documen', 't') into 'document'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'i', 'r', 's', 't', '/w'): 2, ('document', '.', '/w'): 2, ('document', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'i', 'r', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('document', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w', 'do', 'doc', 'docu', 'docum', 'docume', 'documen', 'document']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume', ('docume', 'n'): 'documen', ('documen', 't'): 'document'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 13/15\n",
            "Top 5 Pair Frequencies: [(('i', 'r'), 3), (('.', '/w'), 3), (('d', '/w'), 3), (('T', 'h'), 2), (('h', 'is/w'), 2)]\n",
            "Found Best Pair: ('i', 'r') with Frequency: 3\n",
            "Merging ('i', 'r') into 'ir'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'ir', 's', 't', '/w'): 2, ('document', '.', '/w'): 2, ('document', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'ir', 'd', '/w'): 1, ('o', 'n', 'e', '.', '/w'): 1, ('I', 's/w'): 1, ('document', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w', 'do', 'doc', 'docu', 'docum', 'docume', 'documen', 'document', 'ir']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume', ('docume', 'n'): 'documen', ('documen', 't'): 'document', ('i', 'r'): 'ir'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 14/15\n",
            "Top 5 Pair Frequencies: [(('.', '/w'), 3), (('d', '/w'), 3), (('T', 'h'), 2), (('h', 'is/w'), 2), (('f', 'ir'), 2)]\n",
            "Found Best Pair: ('.', '/w') with Frequency: 3\n",
            "Merging ('.', '/w') into './w'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'ir', 's', 't', '/w'): 2, ('document', './w'): 2, ('document', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '/w'): 1, ('A', 'n', 'd', '/w'): 1, ('th', 'is/w'): 2, ('th', 'ir', 'd', '/w'): 1, ('o', 'n', 'e', './w'): 1, ('I', 's/w'): 1, ('document', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w', 'do', 'doc', 'docu', 'docum', 'docume', 'documen', 'document', 'ir', './w']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume', ('docume', 'n'): 'documen', ('documen', 't'): 'document', ('i', 'r'): 'ir', ('.', '/w'): './w'}\n",
            "------------------------------\n",
            "\n",
            "Merge Iteration 15/15\n",
            "Top 5 Pair Frequencies: [(('d', '/w'), 3), (('T', 'h'), 2), (('h', 'is/w'), 2), (('f', 'ir'), 2), (('ir', 's'), 2)]\n",
            "Found Best Pair: ('d', '/w') with Frequency: 3\n",
            "Merging ('d', '/w') into 'd/w'\n",
            "Splits after merge: {('T', 'h', 'is/w'): 2, ('is/w',): 3, ('the/w',): 4, ('f', 'ir', 's', 't', '/w'): 2, ('document', './w'): 2, ('document', '/w'): 1, ('s', 'e', 'c', 'o', 'n', 'd/w'): 1, ('A', 'n', 'd/w'): 1, ('th', 'is/w'): 2, ('th', 'ir', 'd/w'): 1, ('o', 'n', 'e', './w'): 1, ('I', 's/w'): 1, ('document', '?', '/w'): 1}\n",
            "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '/w', 's/w', 'is/w', 'th', 'the', 'the/w', 'do', 'doc', 'docu', 'docum', 'docume', 'documen', 'document', 'ir', './w', 'd/w']\n",
            "Updated Merges: {('s', '/w'): 's/w', ('i', 's/w'): 'is/w', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '/w'): 'the/w', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume', ('docume', 'n'): 'documen', ('documen', 't'): 'document', ('i', 'r'): 'ir', ('.', '/w'): './w', ('d', '/w'): 'd/w'}\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZcoVLcfB7fQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}